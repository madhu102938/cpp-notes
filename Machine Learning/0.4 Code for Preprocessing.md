```python
# -*- coding: utf-8 -*-  
"""Copy of data_preprocessing_tools.ipynb  
  
Automatically generated by Colaboratory.  
  
Original file is located at  
    https://colab.research.google.com/drive/1fYf3_H_zdbWyeF9AoFLjIgh_2Kkc8g-6  
# Data Preprocessing Tools  
  
## Importing the libraries  
"""  
  
import pandas as pd  
import numpy as np  
import matplotlib.pyplot as plt  
  
"""## Importing the dataset"""  
  
dataset = pd.read_csv('Data.csv')  
x = dataset.iloc[:, :-1].values  
y = dataset.iloc[:, -1].values  
  
print(x)  
  
print(y)  
  
"""## Taking care of missing data"""  
  
from sklearn.impute import SimpleImputer  
si = SimpleImputer(missing_values=np.nan, strategy='mean')  
si.fit(x[:, 1:3])  
x[:, 1:3] = si.transform(x[:, 1:3])  
  
print(x)  
  
"""## Encoding categorical data  
  
### Encoding the Independent Variable  
"""  
  
from sklearn.compose import ColumnTransformer  
from sklearn.preprocessing import OneHotEncoder  
ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')
x = np.array(ct.fit_transform(x))  
  
print(x)  
  
"""### Encoding the Dependent Variable"""  
  
from sklearn.preprocessing import LabelEncoder  
le = LabelEncoder()  
y = le.fit_transform(y)  
  
print(y)  
  
"""## Splitting the dataset into the Training set and Test set"""  
  
from sklearn.model_selection import train_test_split  
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)  
  
print(x_train)  
  
print(x_test)  
  
print(y_train)  
  
print(y_test)  
  
"""## Feature Scaling"""  
  
from sklearn.preprocessing import StandardScaler  
ss = StandardScaler()  
x_train[:, 3:] = ss.fit_transform(x_train[:, 3:])  
x_test[:, 3:] = ss.transform(x_test[:, 3:])  
  
print(x_train)  
  
print(x_test)
```